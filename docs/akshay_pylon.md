Your real problem isn't that AI coding tools are slow or unhelpful — they save you massive time overall. The problem is that they've introduced a new, invisible tax: a trust deficit.

You write detailed, structured specs. The tools get you 70-80% of the way there fast. But they silently drop requirements, and worse, they can't reliably catch their own mistakes even when you explicitly ask them to verify. So you've had to build an entire parallel workflow — verification passes, escalating prompts with failure examples, and "weird" edge-case testing — just to close the gap between what you asked for and what you actually got.

The deepest cut is the hidden bugs you know are there but haven't found yet. That ambient anxiety means you can never fully trust the output, which means you're spending 2-3x the spec-writing time on debugging and verification. The tool gave you speed but took away confidence, and you're paying for that confidence back with your own time and vigilance.

The emotional core: you did your part — you wrote the spec clearly, even numbered the steps — and the tool still let you down silently. That's not just inefficiency, it's a small betrayal of the deal you thought you were making.
